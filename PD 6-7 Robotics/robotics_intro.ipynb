{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c1d9317",
   "metadata": {},
   "source": [
    "# Introduction to Robotics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed35ee",
   "metadata": {},
   "source": [
    "In this assignment, you will set up important tools to be used for robotics development such as an Ubuntu Virtual Machine, ROS, Gazebo, and the FBX Python SDK. These tools will be extremely valuable for the future as you begin forming code for your robotics projects. In part one, we will focus on ROS and Gazebo. As an example, we will look at the TurtleBot robot in the Gazebo simulator. We can use ROS to control this robot despite not having a physical model. In part two, we will work with motion capture data, which will be one type of training data used to develop the learning model for our robot. This file is in a format called 'fbx', and so we must use Maya or Blender to visualize this data. As an example, we will also look at how to view this video data with OpenCV. \n",
    "\n",
    "Now, let's dive into Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "795147bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/samanthasudhoff/anaconda3/lib/python3.11/site-packages/huggingface_hub-0.20.2-py3.8.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pip in ./anaconda3/lib/python3.11/site-packages (23.2.1)\n",
      "Collecting pip\n",
      "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/8a/6a/19e9fe04fca059ccf770861c7d5721ab4c2aebc539889e97c7977528a53b/pip-24.0-py3-none-any.whl.metadata\n",
      "  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "\u001b[33m  WARNING: The scripts pip, pip3 and pip3.11 are installed in '/Users/samanthasudhoff/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed pip-24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c13c91",
   "metadata": {},
   "source": [
    "## Part 1: ROS & Gazebo Simulator\n",
    "\n",
    "ROS stands for Robot Operating System, and it is a set of libraries for robotics programming. ROS is incredibly useful for robotics due to the sheer number of useful packages which ROS offers. ROS allows for easier communication between robot hardware and computer software, provides tools for visualization and graphing capabilities, and much more. \n",
    "\n",
    "It is easist (as well as recommended) to use ROS with Linux systems. If you are on Mac OS, you are out of luck because there is no Mac OS support. If you are on Windows, you can *tecnically* use ROS, but it is still recommended to use Ubuntu. This is because some packages don't yet exist for Windows, and using the Linux version is also faster than the Windows version. If you do not already use Ubuntu, this means that you will need to set up an Ubuntu Linux VM (Virtual Machine). I personally use VirtualBox for this purpose, although VMWare also works well. If you are unfamiliar with the concept of virtual machines, it is essentially another computer running within your computer (aka computer emulator). This way, you do not need a physical Ubuntu machine. \n",
    "\n",
    "Here is a brief summary of the steps needed to download Ubuntu on a VirtualBox VM:\n",
    "\n",
    "1) Download VirtualBox 7: https://www.virtualbox.org/wiki/Downloads\n",
    "2) Download an Ubuntu image: https://releases.ubuntu.com/20.04.6/?_gl=1*1t7f9g4*_gcl_au*MTk1NDQxMjYyMS4xNzA4NjY0Nzg5&_ga=2.215980757.35529440.1715893260-314673279.1715893260 (use the 20.04 LTS version Focal Fossa)\n",
    "   NOTE: It is important to use the 20.04 version, as the current LTS version is NOT compatible with ROS. \n",
    "3) Create a virtual machine by running VirtualBox and clicking the blue \"New\" button.\n",
    "    -Name this virtual machine \"Ubuntu\" or something similar\n",
    "    -For the ISO image, select your downloaded Ubuntu image\n",
    "    -The type should be Linux, and the version should be Ubuntu (64-bit)\n",
    "    -When creating your user profile on the next page titled \"Unattended Guest OS Install Setup\", make sure to change the username and password so you can have sudo access in the future.\n",
    "    -For resource specifications, use 8 GB RAM, 4 CPUs, and at least 25 GB Hard disc size\n",
    "4) Click start to launch your newly created virtual machine\n",
    "\n",
    "More detailed installation instructions can be found through the following link: https://ubuntu.com/tutorials/how-to-run-ubuntu-desktop-on-a-virtual-machine-using-virtualbox#1-overview. \n",
    "\n",
    "After installing Ubuntu, we can begin installation of our ROS software. We will download the Noetic Ninjemys version (Latest ROS 1 LTS). This can be done by simply opening the terminal of your Ubuntu VM and running the following command:\n",
    "\n",
    "___________________________________________________________________________________________\n",
    "wget -c https://raw.githubusercontent.com/qboticslabs/ros_install_noetic/master/ros_install_noetic.sh && chmod +x ./ros_install_noetic.sh && ./ros_install_noetic.sh\n",
    "___________________________________________________________________________________________\n",
    "\n",
    "The above line installs the ROS software all in one step.\n",
    "\n",
    "Note that if you are getting an error message for the above step, or for any steps due to lack of sudoer access, simply type the following command to switch to the root user:\n",
    "___________________________________________________________________________________________\n",
    "su root\n",
    "___________________________________________________________________________________________\n",
    "\n",
    "Next, we will install one additional tool called 'catkin-tools'. This tool makes it easier to install and build ROS packages. To do so, type the following line into the terminal:\n",
    "\n",
    "___________________________________________________________________________________________\n",
    "\n",
    "sudo apt-get install python3-catkin-tools\n",
    "___________________________________________________________________________________________\n",
    "\n",
    "Now, we will install a software called 'TurtleBot', which will be used as an example robot that we can move around within the Gazebo simulator. TurtleBot is a physical robot which you can purchase, but we will be using a simulated version instead. To install our Turtlebot, we will first do the following steps:\n",
    "\n",
    "___________________________________________________________________________________________\n",
    "sudo apt install ros-noetic-hls-lfcd-lds-driver\n",
    "sudo apt install ros-noetic-dynamixel-sdk\n",
    "sudo apt install ros-noetic-turtlebot3-msgs\n",
    "___________________________________________________________________________________________\n",
    "\n",
    "Note that if you are experiencing any errors with ROS + TurtleBot setup, try typing the setup commands 3.1.2 - 3.1.4 from the following link: https://emanual.robotis.com/docs/en/platform/turtlebot3/quick-start/#pc-setup instead. \n",
    "\n",
    "Next, we will set up our source folder. Type the following into your terminal (line by line):\n",
    "___________________________________________________________________________________________\n",
    "mkdir -p ~/catkin_ws/src\n",
    "cd ~/catkin_ws/src/\n",
    "git clone https://github.com/ROBOTIS-GIT/turtlebot3_msgs.git\n",
    "git clone https://github.com/ROBOTIS-GIT/turtlebot3.git\n",
    "cd ~/catkin_ws && catkin_make\n",
    "___________________________________________________________________________________________\n",
    "\n",
    "The above lines create the catkin workspace for the TurtleBot simulator which we will use as our example. \n",
    "\n",
    "We will be using the burger model of the TurtleBot3. Let's edit the bashrc file to add this model setting: \n",
    "\n",
    "___________________________________________________________________________________________\n",
    "gedit ~/.bashrc\n",
    "___________________________________________________________________________________________\n",
    "\n",
    "\n",
    "Now, we can add the following line to the very bottom of our bashrc file: export TURTLEBOT3_MODEL=burger \n",
    "\n",
    "Save the file and close out.\n",
    "\n",
    "Next, let's reload .bashrc with the following command:\n",
    "\n",
    "___________________________________________________________________________________________\n",
    "source ~/.bashrc\n",
    "___________________________________________________________________________________________\n",
    "\n",
    "\n",
    "Finally, we will download the TurtleBot3 simulation files into our sourcecode folder:\n",
    "\n",
    "___________________________________________________________________________________________\n",
    "cd ~/catkin_ws/src/\n",
    "git clone https://github.com/ROBOTIS-GIT/turtlebot3_simulations.git\n",
    "cd ~/catkin_ws && catkin_make\n",
    "___________________________________________________________________________________________\n",
    "\n",
    "Now that we have downloaded our ROS software and TurtleBot3, we can control our TurtleBot and move it around using the Gazebo simulator. TurtleBot is a physical robot available for purchase, but we are still able to manuever a simulated TurtleBot using ROS and Gazebo. This is why ROS and Gazebo are so important, as they allow us to train and path-plan for our robot without actually needing the physical robot. To view our burger TurtleBot in a blank world, simply type the following line into the terminal: \n",
    "\n",
    "___________________________________________________________________________________________\n",
    "roslaunch turtlebot3_gazebo turtlebot3_empty_world.launch\n",
    "___________________________________________________________________________________________\n",
    "\n",
    "You should now successfully be able to see a Gazebo screen, where your TurtleBot should be visible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f7939",
   "metadata": {},
   "source": [
    "##  Part 1: (ROS & Gazebo) -- Your Submission: \n",
    "\n",
    "Now that you have installed ROS, Gazebo, and TurtleBot, on your Ubuntu VM, it is important to ensure that all of these items have been set up correctly. To do so, you will need to submit several things:\n",
    "\n",
    "First, submit an image of your Gazebo screen after running the instructions given above. Place this image in your folder within the Robot Cello Google Drive. This is to ensure that all of your software has properly been installed.\n",
    "\n",
    "Second, select a different model of the TurtleBot and run the simulation with this model. Figure out which command you need to run to control the robot with your keyboard. \n",
    "\n",
    "Insert this command here: <command>\n",
    "\n",
    "Next, type which model you chose for your TurtleBot: <model> \n",
    "\n",
    "Additionally, note that our initial simulation was run in a blank Gazebo world. Can you use run a simulation using the house map (or the map of your choice)? Insert an image of this running map in the same folder as your first image on Google Drive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c711ee3b",
   "metadata": {},
   "source": [
    "## Part 2: Handling Motion Capture Data with Python\n",
    "\n",
    "For our project, we will be using motion capture data to train our robot to play the cello (along with several other forms of training data). Therefore, it is important to be able to handle, manipulate, and analyze this data using Python.\n",
    "\n",
    "The format of our motion capture data is using .fbx files. This data will be shared to members on Google Drive for future use. First, navigae to the \"Robot Cello\" folder, and then navigate to the \"Data\" subfolder.\n",
    "\n",
    "NOTE: If you are having trouble accessing the \"Robot Cello\" folder on Google Drive, send me (Samantha Sudhoff) your gmail through Teams so the folder can shared with you. \n",
    "\n",
    "First, we will download Maya, an animation software which we can use to visualize our .fbx file. Through Purdue, each student has access to Autodesk software through educational licensing. Autodesk software includes Maya as well as many other products such as AutoCAD. To sign into Autodesk go to the following link: https://accounts.autodesk.com/logon?resume=%2Fas%2F70d2Hm9lFY%2Fresume%2Fas%2Fauthorization.ping&spentity=null#username using your Purdue email. You might need to make a new account. Once you have done so, you should be able to download Maya for free by going to the education Autodesk page and searching for the Maya download: https://www.autodesk.com/education/edu-software/overview?sorting=featured&filters=individual#card-maya. Once you have downloaded this software, you can follow the Maya installation instructions. \n",
    "\n",
    "Run Maya and open one of the .fbx files to see what the animated format looks like of our motion capture data. You can even (optionally) synchronize these animated files with the audio recordings also found in the Google Drive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e46fd41",
   "metadata": {},
   "source": [
    "After viewing the animation of the video file, we can download our .fbx file as a .MP4 video and then run this video using OpenCV. To do so, we must first install opencv using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82d7a2f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/samanthasudhoff/anaconda3/lib/python3.11/site-packages/huggingface_hub-0.20.2-py3.8.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opencv-python\n",
      "  Obtaining dependency information for opencv-python from https://files.pythonhosted.org/packages/35/69/b657974ddcbba54d59d7d62b01e60a8b815e35f415b996e4d355be0ac7b4/opencv_python-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl.metadata\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./anaconda3/lib/python3.11/site-packages (from opencv-python) (1.24.3)\n",
      "Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl (55.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c28538",
   "metadata": {},
   "source": [
    "The following code first imports cv2 so we can use the OpenCV library. Then, the code creates a VideoCapture object which we can use to read frames from a video input. We will be reading the frames from our motion capture .MP4 video. Replace the videoName for the VideoCapture object with your own .MP4 file. The cv2.VideoCapture() line opens the camera for video capture. Replace the parameter for VideoCapture() to be the path to your .MP4 file. We will first check if the VideoCapture object we created gets properly opened. Then, we will rescale our image to be smaller and read the frame until the 'q' button is pressed to exit out of the running loop. The function cv2.imshow() will display our frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b5be7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Succefully opened\n",
      "Could not read the frame\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "## NOTE: MODIFY THE LINE BELOW FOR YOUR OWN VIDEO ##\n",
    "## ---------------------------------------------- ##\n",
    "videoName = 'animation2.MP4' # replace this file with your own MP4 file\n",
    "\n",
    "# Creates a VideoCapture Object. Replace 'Downloads/' + videoName with the path to your .MP4 video\n",
    "## NOTE: MODIFY THE LINE BELOW FOR YOUR OWN VIDEO ##\n",
    "## ---------------------------------------------- ##\n",
    "video = cv2.VideoCapture('Downloads/' + videoName)\n",
    "\n",
    "# Checks if the VideoCapture object we created gets properly opened. \n",
    "if video.isOpened():\n",
    "    print('Video Succefully opened')\n",
    "else:\n",
    "    print('Something went wrong check if the video name and path is correct')\n",
    "\n",
    "# Let's name our video window\n",
    "windowName = 'Animation File'\n",
    "cv2.namedWindow(windowName)\n",
    "\n",
    "    \n",
    "# define a scale lvl for visualization\n",
    "scaleLevel = 3 \n",
    "\n",
    "while True:\n",
    "    # read() returns two parameters: a boolean which returns 'True' if the frame gets read correctly, \n",
    "    #                                and the frame itself.\n",
    "    ret,frame = video.read() # reads a single frame \n",
    "    # if ret is false, we couldn't read the frame properly\n",
    "    if not ret: \n",
    "         print(\"Could not read the frame\")   \n",
    "         cv2.destroyWindow(windowName)\n",
    "         break\n",
    "    \n",
    "    rescaled_frame  = frame\n",
    "    \n",
    "    # For this example since we set the scaleLevel to 3 up above, we rescale twice. \n",
    "    # pyrDown() downsamples our image by cutting the image size in half. \n",
    "    # Since we do this twice, we will be decreasing our image size to 1/4 of its original size.\n",
    "    for i in range(scaleLevel-1):\n",
    "        rescaled_frame = cv2.pyrDown(rescaled_frame)\n",
    "    \n",
    "    # imshow() displays our 'rescaled_frame' in the window specified by 'windowName'\n",
    "    cv2.imshow(windowName, rescaled_frame)\n",
    "    \n",
    "    # Essentially, we can press 'q' to quit\n",
    "    waitKey = (cv2.waitKey(1) & 0xFF)\n",
    "    if  waitKey == ord('q'): \n",
    "         print(\"closing video and exiting\")\n",
    "         cv2.destroyWindow(windowName)\n",
    "         video.release()\n",
    "         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a19bd1",
   "metadata": {},
   "source": [
    "Now that we have viewed the .fbx file as an animation on Maya and displayed it as a .MP4 video using OpenCV, we can learn how to use the Autodesk Python FBX SDK. \n",
    "\n",
    "To install The Python FBX SDK, use the following instructions: https://help.autodesk.com/view/FBX/2020/ENU/?guid=FBX_Developer_Help_scripting_with_python_fbx_installing_python_fbx_html\n",
    "\n",
    "First, visit the following link: https://aps.autodesk.com/developer/overview/fbx-sdk\n",
    "\n",
    "Then, follow the download instructions for your device. Make note of where you have downloaded the SDK.\n",
    "\n",
    "Find your 'Autodesk' folder, and then go to the 'FBX Python SDK' subfolder. Inside this subfolder, there should be a file which ends in .whl. \n",
    "\n",
    "Open a terminal window, cd to the location of your .whl file, and type python -m pip install name_of_the_wheel_file.whl. Then, you have successfully installed the FBX Python SDK. \n",
    "\n",
    "Once you have properly downloaded the SDK, you can look at the many examples provided in the FBX SDK sample folder. These will be useful examples in the future if you ever need to clean up or analyze .fbx files when handling training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79806124",
   "metadata": {},
   "source": [
    "## Part 2: (Motion Capture Data) -- Your Submission: \n",
    "\n",
    "For Part 2, first submit a screen recording of your Maya animation to your subfolder in the Robot Cello Google Drive. Then, modify the code above to display your .MP4 video. \n",
    "\n",
    "There is no submission required for the installation of the Python FBX SDK, as this scripting tool will only be used when running files with Blender itself. It is recommended to look through the sample files, as well as optionally download the C++ version of the FBX SDK since the Python version is just a binding. If you choose to download the C++ version, the \"Your First Program\": https://help.autodesk.com/view/FBX/2020/ENU/?guid=FBX_Developer_Help_getting_started_your_first_fbx_sdk_program_html overview is very useful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
